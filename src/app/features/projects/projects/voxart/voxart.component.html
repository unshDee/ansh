<app-project-template
  projectTitle="VoxArt"
  note="Bachelor Thesis Project"
  [technologies]="[
    'BERT',
    'Stable Diffusion v2',
    'PyTorch',
    'Google Cloud Speech-to-Text API',
    'Natural Language Processing',
    'Deep Learning',
  ]"
>
  <div description>
    A <span class="italic">Speech-to-Image Synthesis</span> system that
    transforms spoken language into visual art.
  </div>

  <div content>
    <div class="grid grid-cols-4 gap-4">
      <span class="font-mono text-sm"
        >[<span class="font-bold">Vo</span>ice
        <span class="font-bold">x Art</span>]</span
      >
      <br />
      <div class="text-xl font-serif text-justify col-span-4">
        VoxArt represents a different approach to multimodal AI, seamlessly
        integrating speech recognition with advanced image generation models.
        This bachelor thesis project demonstrates the practical implementation
        of a voice-driven creative tool that transforms spoken descriptions into
        high-quality visual representations using state-of-the-art deep learning
        architectures.
      </div>
    </div>

    <h2 class="text-3xl my-4 mt-10">System Architecture</h2>
    <div class="font-serif text-xl text-justify mb-6">
      The VoxArt system employs a sophisticated three-stage pipeline that
      processes audio input through speech recognition, performs sentiment
      analysis for enhanced context understanding, and generates corresponding
      images using Stable Diffusion v2.
    </div>

    <div class="grid grid-cols-1 gap-4 mb-8">
      <app-window windowTitle="VoxArt Processing Pipeline" class="col-span-1">
        <div class="grid grid-cols-1 lg:grid-cols-3 gap-4">
          <div>
            <h4 class="font-bold pb-2 mb-2 border-b-1">
              [1] Speech Recognition
            </h4>
            <p class="text-sm text-justify">
              Google Cloud Speech-to-Text API converts spoken audio into
              structured text with high accuracy
            </p>
          </div>
          <div>
            <h4 class="font-bold pb-2 mb-2 border-b-1">
              [2] Sentiment Analysis
            </h4>
            <p class="text-sm text-justify">
              BERT model analyzes emotional context and enhances prompt
              understanding
            </p>
          </div>
          <div class="architecture-step">
            <h4 class="font-bold pb-2 mb-2 border-b-1">[3] Image Generation</h4>
            <p class="text-sm text-justify">
              Stable Diffusion v2 synthesizes high-quality images from processed
              text descriptions
            </p>
          </div>
        </div>
      </app-window>
    </div>

    <h2 class="text-3xl my-4 mt-8">Performance Metrics</h2>
    <div class="font-serif text-xl text-justify mb-4">
      Comprehensive evaluation of the VoxArt system demonstrates exceptional
      performance across all integrated components, with strong results in
      sentiment analysis and image generation quality.
    </div>

    <div>
      <app-window
        windowTitle="Component Performance Analysis"
        class="col-span-1"
      >
        <div class="space-y-4 grid grid-cols-1 lg:grid-cols-2 gap-4 mb-8">
          <div>
            <h5 class="font-semibold mb-2 pb-2 border-b-1">
              Sentiment Analysis (BERT)
            </h5>
            <div class="font-mono text-sm space-y-1">
              <div class="flex justify-between">
                <span>Accuracy:</span>
                <span class="font-bold">89.5%</span>
              </div>
              <div class="flex justify-between">
                <span>Precision:</span>
                <span class="font-bold">91.2%</span>
              </div>
              <div class="flex justify-between">
                <span>Recall:</span>
                <span class="font-bold">87.8%</span>
              </div>
              <div class="flex justify-between">
                <span>F1 Score:</span>
                <span class="font-bold">89.4%</span>
              </div>
            </div>
            <div class="text-xs mt-3 text-justify leading-relaxed">
              <strong>Accuracy:</strong> Overall correctness of sentiment
              predictions across all emotional categories.
              <strong>Precision:</strong> Proportion of correctly identified
              sentiments among all positive predictions.
              <strong>Recall:</strong> Ability to identify all relevant
              emotional contexts in speech input.
              <strong>F1 Score:</strong> Harmonic mean balancing precision and
              recall for robust sentiment classification.
            </div>
          </div>
          <div>
            <h5 class="font-semibold mb-2 pb-2 border-b-1">
              Image Generation (Stable Diffusion v2)
            </h5>
            <div class="font-mono text-sm space-y-1">
              <div class="flex justify-between">
                <span>FID Score:</span>
                <span class="font-bold text-green-600">12.6</span>
              </div>
              <div class="flex justify-between">
                <span>Inception Score (IS):</span>
                <span class="font-bold text-green-600">21.4</span>
              </div>
              <div class="flex justify-between">
                <span>LPIPS:</span>
                <span class="font-bold text-green-600">0.17</span>
              </div>
              <div class="flex justify-between">
                <span>SSIM:</span>
                <span class="font-bold text-green-600">0.81</span>
              </div>
              <div class="flex justify-between">
                <span>CLIP Score:</span>
                <span class="font-bold text-green-600">0.32</span>
              </div>
              <div class="flex justify-between">
                <span>Coherence (human eval.):</span>
                <span class="font-bold text-green-600">4.6/5</span>
              </div>
              <div class="flex justify-between">
                <span>Contextual Accuracy:</span>
                <span class="font-bold text-green-600">87%</span>
              </div>
            </div>
            <div class="text-xs mt-3 text-justify leading-relaxed">
              <strong>FID:</strong> Fr√©chet Inception Distance measures realism
              by comparing feature distributions (lower is better).
              <strong>IS:</strong> Inception Score evaluates image quality and
              diversity (higher indicates better generation).
              <strong>LPIPS:</strong> Learned Perceptual Image Patch Similarity
              for human-like quality assessment.
              <strong>SSIM:</strong> Structural Similarity Index measuring
              luminance, contrast, and structure preservation.
              <strong>CLIP Score:</strong> Vision-language model alignment
              between generated images and text descriptions.
              <strong>Coherence:</strong> Human evaluation of visual-semantic
              consistency and artistic quality.
              <strong>Contextual Accuracy:</strong> Correspondence between
              spoken emotional context and visual output.
            </div>
          </div>
        </div>
      </app-window>
    </div>

    <h2 class="text-3xl my-4 mt-8">Technical Implementation</h2>
    <div class="font-serif text-xl text-justify mb-4">
      The implementation leverages cutting-edge technologies to create a robust
      and scalable speech-to-image synthesis system with real-time processing
      capabilities and high-quality output generation.
    </div>

    <div class="grid grid-cols-1 xl:grid-cols-2 gap-4 mb-8">
      <app-window windowTitle="Core Technologies" class="col-span-1">
        <ul class="list-disc pl-4 space-y-2 text-justify">
          <li>
            <strong>Google Cloud Speech-to-Text API:</strong> Advanced speech
            recognition with support for multiple languages and real-time
            processing
          </li>
          <li>
            <strong>BERT (Bidirectional Encoder Representations):</strong>
            Contextual sentiment analysis and natural language understanding
          </li>
          <li>
            <strong>Stable Diffusion v2:</strong> State-of-the-art text-to-image
            generation with high-resolution output capabilities
          </li>
          <li>
            <strong>PyTorch:</strong> Deep learning frameworks for model
            integration and optimization
          </li>
        </ul>
      </app-window>
      <app-window windowTitle="Key Features" class="col-span-1">
        <ul class="list-disc pl-4 space-y-2 text-justify">
          <li>
            <strong>Real-time Processing:</strong> Live audio input with
            immediate transcription and image generation
          </li>
          <li>
            <strong>Multi-language Support:</strong> Recognition and processing
            of various spoken languages
          </li>
          <li>
            <strong>Sentiment-aware Generation:</strong> Enhanced image output
            based on emotional context analysis
          </li>
          <li>
            <strong>User-friendly Interface:</strong> Intuitive voice-driven
            interaction without technical barriers
          </li>
        </ul>
      </app-window>
    </div>

    <h2 class="text-3xl my-4 mt-8">Research Dataset & Methodology</h2>
    <div class="font-serif text-xl text-justify mb-4">
      The evaluation was conducted using a comprehensive research dataset
      specifically designed to test the system's performance across various
      speech patterns, linguistic complexities, and creative description
      scenarios.
    </div>

    <div class="grid grid-cols-1 lg:grid-cols-2 gap-4 mb-8">
      <app-window
        windowTitle="Dataset Characteristics"
        class="col-span-1"
        [initialMinimized]="true"
      >
        <div class="font-mono text-sm space-y-2">
          <div class="flex justify-between">
            <span>Total Utterances:</span>
            <span class="font-bold">500</span>
          </div>
          <div class="flex justify-between">
            <span>Avg. Length:</span>
            <span class="font-bold">10.2 seconds</span>
          </div>
          <div class="flex justify-between">
            <span>Languages:</span>
            <span class="font-bold">Multiple</span>
          </div>
          <div class="flex justify-between">
            <span>Speakeand GPU accelerationrs:</span>
            <span class="font-bold">Various</span>
          </div>
        </div>
        <p class="text-sm mt-2 text-justify">
          Performance metrics calculated based on dataset of 500 utterances
          recorded from various speakers with average length of 10.2 seconds.
        </p>
      </app-window>
      <app-window
        windowTitle="Quality Metrics"
        class="col-span-1"
        [initialMinimized]="true"
      >
        <ul class="list-disc pl-4 space-y-1 text-sm">
          <li>Transcription accuracy measurement</li>
          <li>Word Error Rate (WER) calculation</li>
          <li>Language detection accuracy</li>
          <li>Sentiment classification performance</li>
        </ul>
        <p class="text-sm mt-2 text-justify">
          Word Error Rate measures accuracy of transcribed words compared to
          ground truth. Speaker diarization represents precision of correctly
          identifying different speakers.
        </p>
      </app-window>
      <app-window
        windowTitle="Evaluation Results"
        class="col-span-1 lg:col-span-2"
      >
        <p class="mb-2 text-sm text-justify">
          The comprehensive evaluation demonstrates the system's reliability and
          effectiveness across all performance dimensions, with particularly
          strong results in image generation quality and contextual accuracy.
        </p>
        <div class="tech-spec space-y-2">
          <div class="text-center font-bold text-green-600">
            Overall System Performance: 93.7%
          </div>
          <div class="text-xs text-justify">
            Language detection accuracy indicates precision of correctly
            identifying language spoken in audio
          </div>
        </div>
      </app-window>
    </div>

    <h2 class="text-3xl my-4 mt-8">Implementation Challenges & Solutions</h2>
    <div class="font-serif text-xl text-justify mb-4">
      Developing VoxArt presented several technical challenges, from managing
      real-time processing requirements to ensuring accurate interpretation of
      spoken descriptions and maintaining high-quality visual output.
    </div>

    <div class="grid grid-cols-1 xl:grid-cols-3 gap-4 mb-8 text-justify">
      <app-window windowTitle="Latency Optimization" class="col-span-1">
        <p class="mb-2">
          Implementing efficient pipeline processing to minimize delay between
          speech input and image generation output.
        </p>
        <div class="tech-spec text-sm">
          <strong>Solution:</strong> Asynchronous processing with optimized
          model loading for real-time performance.
        </div>
      </app-window>
      <app-window windowTitle="Speech Accuracy" class="col-span-1">
        <p class="mb-2">
          Achieving high transcription accuracy across different speakers,
          accents, and environmental conditions.
        </p>
        <div class="tech-spec text-sm">
          <strong>Achievement:</strong> 95.6% transcription accuracy with robust
          noise filtering and adaptive recognition algorithms.
        </div>
      </app-window>
      <app-window windowTitle="Visual Quality" class="col-span-1">
        <p class="mb-2">
          Ensuring generated images accurately reflect the semantic content and
          emotional context of spoken descriptions.
        </p>
        <div class="tech-spec text-sm">
          <strong>Result:</strong> 96.7% coherence score with enhanced prompt
          engineering and sentiment-aware generation.
        </div>
      </app-window>
    </div>

    <h2 class="text-3xl my-4 mt-8">Research Contributions</h2>
    <div class="font-serif text-xl text-justify mb-6">
      This thesis project contributes to the field of multimodal AI by
      demonstrating effective integration of speech and vision technologies,
      providing insights into real-time processing requirements, and
      establishing benchmarks for voice-driven creative applications.
    </div>

    <div class="grid grid-cols-1 lg:grid-cols-2 gap-4 mb-8">
      <app-window windowTitle="Novel Approaches" class="col-span-1">
        <ul class="list-disc pl-4 space-y-2">
          <li>
            Integration of sentiment analysis with image generation for
            context-aware synthesis
          </li>
          <li>Real-time multimodal processing pipeline optimization</li>
          <li>Voice-driven creative interface design patterns</li>
          <li>User experience design for creative applications</li>
        </ul>
      </app-window>
      <app-window windowTitle="Evaluation Metrics" class="col-span-1">
        <div>
          <ul class="list-disc pl-4 space-y-2">
            <li>Speech recognition accuracy assessment</li>
            <li>Image generation quality metrics</li>
            <li>User satisfaction and usability studies</li>
            <li>System latency and performance analysis</li>
            <li>Contextual accuracy measurement</li>
          </ul>
        </div>
      </app-window>
    </div>

    <h2 class="text-3xl my-4 mt-8">Future Directions</h2>
    <div class="font-serif text-xl text-justify mb-4">
      The VoxArt project opens several avenues for future research and
      development, including enhanced multimodal understanding, improved
      generation quality, and broader applications in creative and educational
      domains.
    </div>

    <div class="grid grid-cols-1 lg:grid-cols-3 gap-2 mb-8">
      <app-window windowTitle="Enhanced Models" class="col-span-1">
        <div class="text-justify">
          <p>
            Integration of larger, more sophisticated models for improved
            understanding and generation capabilities, including GPT-4 and
            advanced diffusion models.
          </p>
        </div>
      </app-window>
      <app-window windowTitle="Expanded Applications" class="col-span-1">
        <div class="text-justify">
          <p>
            Extension to educational tools, accessibility applications, and
            professional creative workflows including design automation and
            content creation platforms.
          </p>
        </div>
      </app-window>
      <app-window windowTitle="Platform Integration" class="col-span-1">
        <div class="text-justify">
          <p>
            Development of web and mobile applications for broader accessibility
            and user adoption, with cloud-based processing and collaborative
            features.
          </p>
        </div>
      </app-window>
    </div>

    <h2 class="text-3xl my-4 mt-8">Project Impact</h2>
    <div class="font-serif text-xl text-justify mb-6">
      VoxArt demonstrates the potential of voice-driven creative tools and
      contributes to making AI-powered image generation more accessible and
      intuitive for users across different technical backgrounds.
    </div>
  </div>
</app-project-template>
