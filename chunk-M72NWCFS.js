import{a as p,b as L}from"./chunk-Z6VDIYEG.js";import{a as A}from"./chunk-DBS6YHC4.js";import{b as P}from"./chunk-YJJZCYPS.js";import{a as I}from"./chunk-ARLT7E4K.js";import{a as B}from"./chunk-MBTDRT46.js";import{l as _}from"./chunk-CT3WOVP3.js";import"./chunk-KD5KPFK4.js";import{Ba as g,Ga as s,Gb as F,Ka as h,Oa as y,Ra as C,V as b,W as w,Xa as m,bb as i,cb as t,db as o,eb as R,fb as T,kb as x,lb as f,mb as u,nb as e,pb as M,qb as z,sb as E,tb as S,zb as k}from"./chunk-M4WCLFPR.js";var O=["regressionChart"],j=["classificationChart"],U=["classificationReportChart"],G=()=>["Python","scikit-learn","XGBoost","Pandas","NumPy","GridSearchCV","Statistical Analysis"];function q(v,a){v&1&&(i(0,"div",111)(1,"h3",112),e(2," Random Forest Classification Report "),t(),i(3,"div",113)(4,"app-window",114)(5,"div",115)(6,"div",116)(7,"div",117),e(8,"Metric"),t(),i(9,"div",118),e(10,"Class 0"),t(),i(11,"div",118),e(12,"Class 1"),t(),i(13,"div",118),e(14,"Weighted"),t()(),i(15,"div",119)(16,"div",120),e(17,"Precision"),t(),i(18,"div",121),e(19,"0.76"),t(),i(20,"div",121),e(21,"0.88"),t(),i(22,"div",121),e(23,"0.86"),t()(),i(24,"div",122)(25,"div",120),e(26,"Recall"),t(),i(27,"div",121),e(28,"0.54"),t(),i(29,"div",121),e(30,"0.95"),t(),i(31,"div",121),e(32,"0.86"),t()(),i(33,"div",123)(34,"div",120),e(35,"F1-Score"),t(),i(36,"div",124),e(37,"0.63"),t(),i(38,"div",125),e(39," 0.92 "),t(),i(40,"div",124),e(41,"0.85"),t()(),i(42,"div",126)(43,"div",127),e(44," Accuracy: "),i(45,"span",128),e(46,"86.4%"),t()(),i(47,"div",129),e(48," Strong overall performance "),t()()()(),i(49,"app-window",130)(50,"div",131)(51,"div",87)(52,"div",132),e(53," Class 0 (Low Utilization) - 647 samples "),t(),i(54,"div"),e(55," - Lower recall (54%) - some low-use patients misclassified as high "),t(),i(56,"div"),e(57,"- Reasonable precision (76%) - fewer false positives"),t(),i(58,"div"),e(59,"- Indicates data imbalance challenges this class"),t()(),i(60,"div",87)(61,"div",132),e(62," Class 1 (High Utilization) - 2353 samples "),t(),i(63,"div"),e(64," - Excellent recall (95%) - captures high-use patients effectively "),t(),i(65,"div"),e(66,"- Strong precision (88%) - few false alarms"),t(),i(67,"div"),e(68,"- Perfect for resource allocation targeting"),t()()()()()())}var H=class v{constructor(a,n){this.analyticsService=a;this.themeService=n;p.register(...L),k(()=>{let l=this.themeService.theme();setTimeout(()=>{this.updateChartsForTheme(l)},100)})}regressionChart;classificationChart;classificationReportChart;charts=[];showDetailedView=!1;ngOnInit(){this.analyticsService.trackProjectView("Healthcare Utilization Prediction"),this.analyticsService.trackEvent("page_view",{page_title:"Healthcare Utilization Prediction",page_location:"/projects/healthcare-utilization",project_category:"machine-learning"})}ngAfterViewInit(){this.createRegressionChart(),this.createClassificationChart(),this.createClassificationReportChart()}toggleDetailedView(){this.showDetailedView=!this.showDetailedView}ngOnDestroy(){this.charts.forEach(a=>a.destroy())}getThemeColors(){let a=this.themeService.theme()==="dark";return{text:a?"#e0e0e0":"#252525",border:a?"#444444":"#dddddd",background:a?"#1c1c1c":"#ffffff",primary:a?"#fe6060":"#db0000",secondary:a?"#ffffff":"#000000",green:a?"#4ade80":"#15803d",orange:a?"#fb923c":"#ea580c",amber:a?"#fbbf24":"#d97706",yellow:a?"#facc15":"#eab308",blue:a?"#60a5fa":"#2563eb"}}updateChartsForTheme(a){if(this.charts.length===0)return;let n=this.getThemeColors();this.charts.forEach((l,d)=>{l.options.plugins?.title&&(l.options.plugins.title.color=n.text),l.options.plugins?.legend?.labels&&(l.options.plugins.legend.labels.color=n.text),l.options.scales&&Object.values(l.options.scales).forEach(r=>{r&&typeof r=="object"&&("ticks"in r&&r.ticks&&(r.ticks.color=n.text),"title"in r&&r.title&&(r.title.color=n.text),"grid"in r&&r.grid&&(r.grid.color=n.border))}),l.data.datasets.forEach((r,c)=>{d===0?(r.backgroundColor=`${n.primary}15`,r.borderColor=n.primary,r.pointBackgroundColor=n.primary,r.pointBorderColor=n.text):d===1?c===0?(r.backgroundColor=`${n.primary}30`,r.borderColor=n.primary,r.pointBackgroundColor=n.primary,r.pointBorderColor=n.text):c===1?(r.backgroundColor=`${n.amber}30`,r.borderColor=n.amber,r.pointBackgroundColor=n.amber,r.pointBorderColor=n.text):c===2&&(r.backgroundColor=`${n.green}30`,r.borderColor=n.green,r.pointBackgroundColor=n.green,r.pointBorderColor=n.text):d===2&&c===0&&(r.backgroundColor=[n.primary,n.green],r.borderColor=n.text)}),l.update("none")})}createRegressionChart(){let a=this.regressionChart.nativeElement.getContext("2d");if(!a)return;let n=this.getThemeColors(),l={type:"line",data:{labels:[`Linear
Regression`,"ElasticNet","Random Forest","XGBoost"],datasets:[{label:"RMSE (Test)",data:[11131.18,10964.77,12012.17,12298.58],backgroundColor:`${n.primary}15`,borderColor:n.primary,borderWidth:3,pointRadius:6,pointHoverRadius:8,pointBorderWidth:2,pointBackgroundColor:n.primary,pointBorderColor:n.text,tension:.3,fill:!0}]},options:{responsive:!0,maintainAspectRatio:!1,plugins:{title:{display:!1},legend:{display:!0,labels:{color:n.text,font:{size:12}}}},scales:{y:{beginAtZero:!1,ticks:{color:n.text},title:{display:!0,text:"RMSE",color:n.text},grid:{color:n.border}},x:{ticks:{color:n.text},grid:{color:n.border,display:!1}}}}},d=new p(a,l);this.charts.push(d)}createClassificationChart(){let a=this.classificationChart.nativeElement.getContext("2d");if(!a)return;let n=this.getThemeColors(),l={type:"radar",data:{labels:["Accuracy","Precision","Recall","F1 Score"],datasets:[{label:"Logistic Regression",data:[.796,.829,.796,.711],backgroundColor:`${n.primary}30`,borderColor:n.primary,borderWidth:2,pointBackgroundColor:n.primary,pointBorderColor:n.text,pointBorderWidth:2,pointRadius:4,pointHoverRadius:6},{label:"XGBoost",data:[.863,.854,.863,.853],backgroundColor:`${n.amber}30`,borderColor:n.amber,borderWidth:2,pointBackgroundColor:n.amber,pointBorderColor:n.text,pointBorderWidth:2,pointRadius:4,pointHoverRadius:6},{label:"Random Forest",data:[.864,.857,.864,.858],backgroundColor:`${n.green}30`,borderColor:n.green,borderWidth:2,pointBackgroundColor:n.green,pointBorderColor:n.text,pointBorderWidth:2,pointRadius:4,pointHoverRadius:6}]},options:{responsive:!0,maintainAspectRatio:!1,scales:{r:{beginAtZero:!0,max:1,ticks:{color:n.text},grid:{color:n.border}}},plugins:{legend:{labels:{color:n.text,font:{size:12}}}}}},d=new p(a,l);this.charts.push(d)}createClassificationReportChart(){let a=this.classificationReportChart.nativeElement.getContext("2d");if(!a)return;let n=this.getThemeColors(),l={type:"doughnut",data:{labels:[`Class 0 - Low
Utilization`,`Class 1 - High
Utilization`],datasets:[{label:"Sample Distribution",data:[647,2353],backgroundColor:[n.primary,n.green],borderColor:n.text,borderWidth:2,hoverOffset:10}]},options:{responsive:!0,maintainAspectRatio:!1,plugins:{legend:{position:"bottom",labels:{color:n.text,font:{size:12},padding:15}},tooltip:{callbacks:{label:function(r){let c=r.dataset.data.reduce((D,N)=>D+N,0),V=(r.parsed/c*100).toFixed(1);return`${r.label}: ${r.parsed} (${V}%)`}}}}}},d=new p(a,l);this.charts.push(d)}static \u0275fac=function(n){return new(n||v)(h(A),h(_))};static \u0275cmp=y({type:v,selectors:[["app-healthcare-utilization"]],viewQuery:function(n,l){if(n&1&&(x(O,5),x(j,5),x(U,5)),n&2){let d;f(d=u())&&(l.regressionChart=d.first),f(d=u())&&(l.classificationChart=d.first),f(d=u())&&(l.classificationReportChart=d.first)}},decls:727,vars:19,consts:[["regressionChart",""],["classificationChart",""],["classificationReportChart",""],["projectTitle","Healthcare Utilization Prediction","note","Project - Machine Learning for Healthcare",3,"technologies"],["description",""],[1,"italic"],["content",""],[1,"grid","grid-cols-4","gap-4"],[1,"font-serif","text-xl","text-justify","col-span-4"],[1,"text-4xl"],[1,"text-3xl","my-4","mt-10"],[1,"grid","grid-cols-2","gap-4","mb-8"],["windowTitle","Regression Task",1,"col-span-2","lg:col-span-1",3,"initialMinimized"],["windowTitle","Classification Task",1,"col-span-2","lg:col-span-1",3,"initialMinimized"],[1,"grid","grid-cols-1","lg:grid-cols-2","gap-6","mb-8"],[1,"col-span-1"],[1,"font-sans","text-2xl","mb-4"],[1,"font-serif","text-lg","text-justify","mb-6"],["windowTitle","Task"],[1,"space-y-4","font-sans"],[1,"grid","grid-cols-3","gap-2","items-center"],[1,"col-span-full","p-3","border-2","border-(--color-text)","rounded","text-center"],[1,"font-bold","text-sm"],[1,"col-span-3","p-3","bg-(--color-primary)/20","border-2","border-(--color-primary)","rounded","text-center"],[1,"text-xs"],[1,"grid","grid-cols-1","gap-3"],[1,"bg-(--color-bg)","border-2","border-(--color-text)","p-3","rounded"],[1,"font-sans","font-bold","text-lg","mb-1"],[1,"font-sans","text-sm","text-(--color-text)"],[1,"grid","grid-cols-1","lg:grid-cols-2","gap-4","mb-8"],[1,"font-serif","text-lg","text-justify","mb-4"],[1,"grid","grid-cols-1","gap-6","mb-8"],["windowTitle","Step 1: Missing Value Handling",3,"initialMinimized"],[1,"font-sans"],[1,"pb-2","border-b-1","border-(--color-text)/20"],[1,"text-lg","font-bold","mb-2",2,"color","var(--color-primary)"],[1,"text-base"],[1,"grid","grid-cols-1","lg:grid-cols-3","gap-4"],[1,"p-4"],[1,"font-bold","mb-2"],[1,"text-sm","space-y-1"],[1,"font-bold"],[1,"font-mono"],["windowTitle","Step 2: Feature Encoding",3,"initialMinimized"],[1,"text-sm","space-y-2"],[1,"bg-(--color-bg)","p-2","rounded","border","border-(--color-text)/30"],[1,"font-mono","text-xs"],[1,"font-mono","text-xs","mt-1"],[1,"text-xs","italic"],["windowTitle","Step 3: Transformation",3,"initialMinimized"],[1,"grid","grid-cols-1","lg:grid-cols-2","gap-4"],[1,"space-y-4"],[1,"p-4","rounded"],[3,"innerHTML"],[1,"font-bold","mb-3"],[1,"text-sm","space-y-3"],[1,"font-bold","mb-1"],[1,"text-xs","mt-2","italic","pt-2","border-t","border-(--color-text)/20"],["windowTitle","Step 4: Scaling & Validation",3,"initialMinimized"],[1,"mt-2","p-3","bg-(--color-primary)/15","border","border-(--color-primary)"],[1,"text-sm","font-bold","mb-1"],[1,"grid","grid-cols-1","mb-8"],["windowTitle","Model Performance Comparison",1,"col-span-1"],[1,"h-80"],["windowTitle","Linear Regression",1,"col-span-1"],[1,"space-y-2","font-sans","text-lg"],[1,"flex","justify-between"],[1,"text-sm"],[1,"text-xl","font-mono"],[1,""],["windowTitle","ElasticNet",1,"col-span-1"],[1,"text-xl","font-mono",2,"color","var(--color-green)"],["windowTitle","Random Forest",1,"col-span-1"],["windowTitle","XGBoost",1,"col-span-1"],["windowTitle","Model Comparison",1,"col-span-1"],[1,"grid","grid-cols-1","lg:grid-cols-3","gap-4","mb-8"],["windowTitle","Logistic Regression",1,"col-span-1"],[1,"space-2","font-sans","text-lg"],[1,"font-serif","text-xl","text-justify","mb-6"],[1,"space-y-3","font-mono","text-md"],[1,"p-2"],[1,"text-sm","text-zinc-600","dark:text-zinc-400"],["windowTitle","ElasticNet (Best)",1,"col-span-1"],["windowTitle","Random Forest (Best)",1,"col-span-1"],[1,"grid","grid-cols-1","gap-4"],["windowTitle","Best Model: ElasticNet"],[1,"space-y-3","font-sans","text-lg"],[1,"p-3"],[1,"text-sm","font-bold","font-sans","text-(--color-primary)"],[1,"text-2xl","font-bold","font-mono"],[1,"text-sm","text-(--color-text)"],["windowTitle","Model Comparison"],[1,"space-y-2","font-sans","text-md"],[1,"flex","justify-between","items-center","pb-2","border-b","border-(--color-text)/20"],[1,"font-bold",2,"color","var(--color-green)"],[1,"flex","justify-between","items-center"],["windowTitle","Best Model: Random Forest"],["windowTitle","Test Set Distribution & Class Imbalance"],[1,"mb-8"],[1,"px-4","py-2","border-2","border-(--color-text)","bg-(--color-bg)","text-(--color-text)","hover:bg-(--color-text)","hover:text-(--color-bg)","transition-all","duration-300","ease-in-out","font-sans","font-bold",3,"click"],["class","my-8",4,"ngIf"],["windowTitle","RFECV Results",1,"col-span-1"],[1,"font-sans","text-md"],[1,"mb-2"],[1,"text-sm","text-zinc-600","dark:text-zinc-400","mb-3"],[1,"bg-primary/10","dark:bg-primary/20","p-2","rounded","text-sm"],["windowTitle","Feature Interactions",1,"col-span-1"],[1,"bg-green/10","dark:bg-green/20","p-2","rounded","text-sm"],["windowTitle","Regression Insights",1,"col-span-1"],[1,"font-sans","text-md","text-justify","space-y-2","list-disc","list-inside"],["windowTitle","Classification Insights",1,"col-span-1"],[1,"my-8"],[1,"text-2xl","font-sans","mb-6","mt-6"],[1,"grid","grid-cols-1","lg:grid-cols-2","gap-6"],["windowTitle","Precision, Recall & F1-Score"],[1,"space-y-3","font-mono"],[1,"grid","grid-cols-4","gap-2","font-bold","pb-3","border-b-2","border-(--color-text)"],[1,"text-sm","font-sans"],[1,"text-center","text-sm","font-sans"],[1,"grid","grid-cols-4","gap-2","pb-2"],[1,"font-bold","text-sm","font-sans"],[1,"text-center","text-sm"],[1,"grid","grid-cols-4","gap-2","pb-2","border-b","border-(--color-text)/20"],[1,"grid","grid-cols-4","gap-2","pb-3","border-b-2","border-(--color-text)"],[1,"text-center","text-sm","font-bold"],[1,"text-center","text-sm","font-bold",2,"color","var(--color-green)"],[1,"mt-4","pt-4","border-t-2","border-(--color-text)"],[1,"font-bold","text-lg"],[2,"color","var(--color-green)"],[1,"font-sans","text-sm","text-(--color-text)","mt-2"],["windowTitle","Per-Class Insights"],[1,"space-y-0","font-sans","text-sm"],[1,"font-bold","mb-1","text-(--color-primary)"]],template:function(n,l){if(n&1){let d=R();i(0,"app-project-template",3)(1,"div",4)(2,"span",5),e(3,"Predicting healthcare utilization"),t(),e(4," and "),i(5,"span",5),e(6,"medical expenditure"),t(),e(7," using machine learning models on a comprehensive dataset of 108 features from a nationwide U.S. patient survey. "),t(),i(8,"div",6)(9,"div",7)(10,"div",8)(11,"span",9),e(12,"A"),t(),e(13,"rtificial Intelligence and machine learning models have tremendous potential in the healthcare domain for precision medicine, diagnosis, treatment planning, and administrative optimization. This project develops predictive models for healthcare utilization using a dataset compiled from a nationwide survey of U.S. patients. The dataset comprises 108 features spanning demographics, personal characteristics, and health-related information, providing a comprehensive view of patient profiles. The project addresses both "),i(14,"span",5),e(15,"regression"),t(),e(16," (predicting total medical expenditure) and "),i(17,"span",5),e(18,"classification"),t(),e(19," (determining low vs. high healthcare utilization) tasks through rigorous preprocessing and feature engineering. "),t()(),i(20,"h2",10),e(21,"Project Objectives"),t(),i(22,"div",11)(23,"app-window",12),e(24," Predict the continuous variable of total medical expenditure in US dollars to understand spending patterns and identify high-cost patients. "),t(),i(25,"app-window",13),e(26," Classify patients into low or high healthcare utilization categories to enable targeted interventions and resource allocation. "),t()(),i(27,"h2",10),e(28,"ML Pipeline Overview"),t(),i(29,"div",14)(30,"div",15)(31,"h3",16),e(32,"Four-Stage Pipeline"),t(),i(33,"div",17),e(34," The ML workflow is structured in four sequential stages, from raw data to final model selection and deployment readiness. "),t(),i(35,"app-window",18)(36,"div",19)(37,"div",20)(38,"div",21)(39,"div",22),e(40,"108 Features"),t()(),i(41,"div",23)(42,"div",22),e(43,"Regression"),t(),i(44,"div",24),e(45,"Medical Cost Prediction"),t()(),i(46,"div",23)(47,"div",22),e(48,"Classification"),t(),i(49,"div",24),e(50,"Utilization Category"),t()()()()()(),i(51,"div",15)(52,"div",25)(53,"div",26)(54,"div",27),e(55," Stage 1: Data Analysis "),t(),i(56,"div",28),e(57," EDA, correlation matrix, statistical significance testing "),t()(),i(58,"div",26)(59,"div",27),e(60," Stage 2: Preprocessing "),t(),i(61,"div",28),e(62," Encoding, scaling, transformation, feature engineering "),t()(),i(63,"div",26)(64,"div",27),e(65," Stage 3: Model Training "),t(),i(66,"div",28),e(67," GridSearchCV tuning, cross-validation, parameter optimization "),t()(),i(68,"div",26)(69,"div",27),e(70," Stage 4: Evaluation "),t(),i(71,"div",28),e(72," Performance metrics, model comparison, best selection "),t()()()()(),i(73,"h2",10),e(74,"Data Analysis and Preprocessing"),t(),i(75,"div",29)(76,"div",15)(77,"h3",16),e(78,"Exploratory Data Analysis"),t(),i(79,"div",30),e(80," Extensive EDA was conducted on all 108 features using statistical summaries, visualizations (boxplots, regression plots, heatmaps), correlation analysis, and statistical testing (ANOVA, T-tests, chi-square) to identify key predictors. "),t()(),i(81,"div",15)(82,"h3",16),e(83,"Statistical Testing"),t(),i(84,"div",30),e(85," ANOVA, T-tests, and chi-square tests were used to assess the significance of categorical features in relation to target variables, guiding feature selection for model development. "),t()()(),i(86,"h3",16),e(87,"Data Preprocessing Pipeline"),t(),i(88,"div",17),e(89," The preprocessing pipeline transformed raw survey data through four critical stages, each addressing specific data quality and feature engineering challenges to prepare the 108 features for optimal model performance. "),t(),i(90,"div",31)(91,"app-window",32)(92,"div",33)(93,"div",34)(94,"div",35),e(95," Context-Aware Imputation Strategy "),t(),i(96,"div",36),e(97,` Survey data contains special codes (-1, -2, -7) indicating "inapplicable", "don't know", and "refused" responses. Each code was interpreted in context before applying appropriate imputation methods. `),t()(),i(98,"div",37)(99,"div",38)(100,"div",39),e(101,"Special Code Interpretation"),t(),i(102,"div",40)(103,"div")(104,"span",41),e(105,"-1"),t(),e(106,": Inapplicable (logical skip) "),t(),i(107,"div")(108,"span",41),e(109,"-2"),t(),e(110,": Don't know (true missing) "),t(),i(111,"div")(112,"span",41),e(113,"-7"),t(),e(114,": Refused to answer"),t()()(),i(115,"div",38)(116,"div",39),e(117,"Continuous Variables"),t(),i(118,"div",40)(119,"div")(120,"strong"),e(121,"Mean"),t(),e(122,": Normally distributed"),t(),i(123,"div")(124,"strong"),e(125,"Median"),t(),e(126,": Skewed distributions"),t(),i(127,"div"),e(128,"Example: "),i(129,"span",42),e(130,"INCOME, AGE"),t()()()(),i(131,"div",38)(132,"div",39),e(133,"Categorical Variables"),t(),i(134,"div",40)(135,"div")(136,"strong"),e(137,"Mode"),t(),e(138,": Most frequent value"),t(),i(139,"div"),e(140,"Preserves distribution"),t(),i(141,"div"),e(142," Example: "),i(143,"span",42),e(144,"REGION, MARITAL_STATUS"),t()()()(),i(145,"div",38)(146,"div",39),e(147,"Value Interpretation"),t(),i(148,"div",40)(149,"div"),e(150,"Contextual interpretation of categorical codes"),t(),i(151,"div")(152,"strong"),e(153,"Example:"),t(),e(154," Binary values (1, 2)"),t(),i(155,"div"),e(156,'\u2192 Mapped to "Yes"/"No" based on feature context'),t()()()()()(),i(157,"app-window",43)(158,"div",33)(159,"div",34)(160,"div",35),e(161," Multi-Strategy Encoding Approach "),t(),i(162,"div",36),e(163," Different encoding techniques were applied based on feature cardinality and relationship to target variables, optimizing information retention while preventing dimensionality explosion. "),t()(),i(164,"div",37)(165,"div",38)(166,"div",39),e(167,"Label Encoding"),t(),i(168,"div",44)(169,"div")(170,"strong"),e(171,"Used for:"),t(),e(172," Binary features"),t(),i(173,"div",45)(174,"div",46),e(175,"SEX: Male \u2192 0, Female \u2192 1"),t(),i(176,"div",47),e(177," MARRIED: No \u2192 0, Yes \u2192 1 "),t()(),i(178,"div",48),e(179,"Preserves natural ordering"),t()()(),i(180,"div",38)(181,"div",39),e(182,"One-Hot Encoding"),t(),i(183,"div",44)(184,"div")(185,"strong"),e(186,"Used for:"),t(),e(187," Nominal categories (\u226410 values) "),t(),i(188,"div",45)(189,"div",46),e(190," REGION: Northeast, Midwest, "),t(),i(191,"div",46),e(192," South, West \u2192 4 binary cols "),t()(),i(193,"div",48),e(194,"Prevents ordinal assumptions"),t()()(),i(195,"div",38)(196,"div",39),e(197,"Target Encoding"),t(),i(198,"div",44)(199,"div")(200,"strong"),e(201,"Used for:"),t(),e(202," High-cardinality features"),t(),i(203,"div",45)(204,"div",46),e(205,"Mean target per category"),t(),i(206,"div",47),e(207," + smoothing to avoid overfitting "),t()(),i(208,"div",48),e(209,"Captures target relationship"),t()()()()()(),i(210,"app-window",49)(211,"div",33)(212,"div",34)(213,"div",35),e(214," Distribution Normalization & Feature Engineering "),t(),i(215,"div",36),e(216," Applied mathematical transformations to address skewness, create meaningful feature groups, and improve model convergence by reshaping distributions closer to normal. "),t()(),i(217,"div",50)(218,"div",51)(219,"div",52)(220,"div",39),e(221,"Logarithmic Transforms"),t(),i(222,"div",44)(223,"div")(224,"strong"),e(225,"Target:"),t(),e(226," Highly skewed features (income, expenditure) "),t(),i(227,"div",45)(228,"div",24),o(229,"span",53),E(230,"safeLatex"),t(),i(231,"div",47),e(232," Normalizes distribution for improved stability "),t()(),i(233,"div",24)(234,"strong"),e(235,"Impact:"),t(),e(236," Improved regression stability and reduced outlier influence "),t()()(),i(237,"div",38)(238,"div",39),e(239,"Binning Strategies"),t(),i(240,"div",44)(241,"div")(242,"strong"),e(243,"Created:"),t(),e(244," Categorical age groups from continuous age "),t(),i(245,"div",45)(246,"div",46),e(247," 0-17, 18-30, 31-45, 46-64, 65+ "),t()(),i(248,"div",24)(249,"strong"),e(250,"Benefit:"),t(),e(251," Captures non-linear age effects on healthcare utilization "),t()()()(),i(252,"div",38)(253,"div",54),e(254,"Feature Engineering Examples"),t(),i(255,"div",55)(256,"div")(257,"div",56),e(258,"Income Consolidation"),t(),i(259,"div",24),e(260," Grouped TOT_INCOME and FAM_INCOME together to reduce dimensionality while preserving economic information "),t()(),i(261,"div")(262,"div",56),e(263,"Chronic Condition Count"),t(),i(264,"div",24),e(265," Aggregated binary indicators (diabetes, hypertension, heart disease) into single numeric feature "),t()(),i(266,"div")(267,"div",56),e(268,"Healthcare Access Score"),t(),i(269,"div",24),e(270," Combined insurance status, regular provider, and visit frequency "),t()(),i(271,"div")(272,"div",56),e(273,"Socioeconomic Index"),t(),i(274,"div",24),e(275," Weighted combination of income, education, and employment "),t()(),i(276,"div",57)(277,"strong"),e(278,"Result:"),t(),e(279," Domain-specific engineered features added to enhance model expressiveness "),t()()()()()(),i(280,"app-window",58)(281,"div",33)(282,"div",34)(283,"div",35),e(284," Normalization & Multicollinearity Check "),t(),i(285,"div",36),e(286," Final preprocessing stage ensuring features are on comparable scales and free from harmful collinearity that could destabilize model training and interpretation. "),t()(),i(287,"div",37)(288,"div",38)(289,"div",39),e(290,"Min-Max Scaling"),t(),i(291,"div",44)(292,"div")(293,"strong"),e(294,"Range:"),t(),e(295," [0, 1]"),t(),i(296,"div",45)(297,"div",24),o(298,"span",53),E(299,"safeLatex"),t()(),i(300,"div",24)(301,"strong"),e(302,"Applied to:"),t(),e(303," Tree-based models (Random Forest, XGBoost) "),t(),i(304,"div",48),e(305," Preserves zero values and distributional shape "),t()()(),i(306,"div",38)(307,"div",39),e(308,"Z-Score Normalization"),t(),i(309,"div",44)(310,"div")(311,"strong"),e(312,"Mean:"),t(),e(313," 0, "),i(314,"strong"),e(315,"Std:"),t(),e(316," 1"),t(),i(317,"div",45)(318,"div",24),o(319,"span",53),E(320,"safeLatex"),t()(),i(321,"div",24)(322,"strong"),e(323,"Applied to:"),t(),e(324," Linear models, Logistic Regression "),t(),i(325,"div",48),e(326," Critical for gradient descent convergence "),t()()(),i(327,"div",38)(328,"div",39),e(329,"VIF Analysis"),t(),i(330,"div",44)(331,"div")(332,"strong"),e(333,"Threshold:"),t(),e(334," VIF < 10"),t(),i(335,"div",45)(336,"div",46),e(337,"Removed features with"),t(),i(338,"div",46),e(339,"VIF > 10 threshold"),t()(),i(340,"div",24)(341,"strong"),e(342,"Result:"),t(),e(343," Eliminated multicollinearity, improved coefficient stability "),t()()()(),i(344,"div",59)(345,"div",60),e(346,"Outlier Handling Strategy"),t(),i(347,"div",24),e(348," Winsorization at 1st and 99th percentiles for extreme values in expenditure and income features, preserving 98% of data while reducing leverage of statistical outliers on regression models. "),t()()()()(),i(349,"h2",10),e(350,"Machine Learning Models"),t(),i(351,"h3",16),e(352,"Regression Models (RMSE Focus)"),t(),i(353,"div",61)(354,"app-window",62)(355,"div",63),o(356,"canvas",null,0),t()()(),i(358,"div",29)(359,"app-window",64)(360,"div",65)(361,"div",66)(362,"div")(363,"strong"),e(364,"Role:"),t(),i(365,"div"),e(366,"Baseline model"),t(),i(367,"div",67),e(368,"Simple, interpretable approach"),t()(),i(369,"div")(370,"div",68),e(371,"11,131.18"),t(),i(372,"div",69),e(373,"RMSE"),t()()()()(),i(374,"app-window",70)(375,"div",65)(376,"div",66)(377,"div")(378,"strong"),e(379,"Strength:"),t(),i(380,"div"),e(381,"Balanced regularization"),t(),i(382,"div",67),e(383,"L1 + L2 penalties combined"),t()(),i(384,"div")(385,"div",71),e(386," 10,964.77 "),t(),i(387,"div",69),e(388,"RMSE"),t()()()()(),i(389,"app-window",72)(390,"div",65)(391,"div",66)(392,"div")(393,"strong"),e(394,"Approach:"),t(),i(395,"div"),e(396,"Ensemble learning"),t(),i(397,"div",67),e(398,"Multiple decision trees"),t()(),i(399,"div")(400,"div",68),e(401,"12,012.17"),t(),i(402,"div",69),e(403,"RMSE"),t()()()()(),i(404,"app-window",73)(405,"div",65)(406,"div",66)(407,"div")(408,"strong"),e(409,"Method:"),t(),i(410,"div"),e(411,"Gradient boosting"),t(),i(412,"div",67),e(413,"Sequential tree correction"),t()(),i(414,"div")(415,"div",68),e(416,"12,298.58"),t(),i(417,"div",69),e(418,"RMSE"),t()()()()()(),i(419,"h3",16),e(420," Classification Models (F1-Score Focus) "),t(),i(421,"div",61)(422,"app-window",74)(423,"div",63),o(424,"canvas",null,1),t()()(),i(426,"div",75)(427,"app-window",76)(428,"div",77)(429,"div",66)(430,"div")(431,"strong"),e(432,"Role"),t(),i(433,"div"),e(434,"Baseline classifier"),t(),i(435,"div",67),e(436,"Simple binary classifier"),t()(),i(437,"div")(438,"div",68),e(439,"0.711"),t(),i(440,"div",69),e(441,"F1 Score"),t()()()()(),i(442,"app-window",73)(443,"div",77)(444,"div",66)(445,"div")(446,"strong"),e(447,"Method:"),t(),i(448,"div"),e(449,"Gradient boosting"),t(),i(450,"div",67),e(451,"Sequential optimization"),t()(),i(452,"div")(453,"div",68),e(454,"0.853"),t(),i(455,"div",69),e(456,"F1 Score"),t()()()()(),i(457,"app-window",72)(458,"div",77)(459,"div",66)(460,"div")(461,"strong"),e(462,"Strength:"),t(),i(463,"div"),e(464,"Ensemble diversity"),t(),i(465,"div",67),e(466,"Multiple trees averaging"),t()(),i(467,"div")(468,"div",71),e(469," 0.858 "),t(),i(470,"div",69),e(471,"F1 Score"),t()()()()()(),i(472,"h2",10),e(473,"Model Selection & Hyperparameter Tuning"),t(),i(474,"div",78),e(475," GridSearchCV was employed to systematically tune hyperparameters for each model, evaluating parameter combinations using cross-validation. "),t(),i(476,"h3",16),e(477,"Regression Configuration"),t(),i(478,"div",29)(479,"app-window",64)(480,"div",79)(481,"div",80)(482,"strong"),e(483,"fit_intercept:"),t(),e(484," False"),t(),i(485,"div",81),e(486," Reduces RMSE while maintaining interpretability. Balanced fit without forcing the line through origin. "),t()()(),i(487,"app-window",82)(488,"div",79)(489,"div",80)(490,"strong"),e(491,"alpha:"),t(),e(492," 0.1"),o(493,"br"),i(494,"strong"),e(495,"l1_ratio:"),t(),e(496," 0.9 "),t(),i(497,"div",81),e(498," 90% L1 + 10% L2 penalty. Optimal balance between feature selection and regularization. "),t()()(),i(499,"app-window",72)(500,"div",79)(501,"div",80)(502,"strong"),e(503,"max_depth:"),t(),e(504," 10"),o(505,"br"),i(506,"strong"),e(507,"min_samples_split:"),t(),e(508," 5"),o(509,"br"),i(510,"strong"),e(511,"n_estimators:"),t(),e(512," 200 "),t(),i(513,"div",81),e(514," Effective bias-variance trade-off. 200 trees with reasonable depth constraints. "),t()()(),i(515,"app-window",73)(516,"div",79)(517,"div",80)(518,"strong"),e(519,"learning_rate:"),t(),e(520," 0.1"),o(521,"br"),i(522,"strong"),e(523,"max_depth:"),t(),e(524," 3"),o(525,"br"),i(526,"strong"),e(527,"n_estimators:"),t(),e(528," 100"),o(529,"br"),i(530,"strong"),e(531,"subsample:"),t(),e(532," 0.8 "),t(),i(533,"div",81),e(534," Conservative settings. Shallow trees prevent overfitting while capturing patterns. "),t()()()(),i(535,"h3",16),e(536,"Classification Configuration"),t(),i(537,"div",75)(538,"app-window",76)(539,"div",79)(540,"div",80)(541,"strong"),e(542,"C:"),t(),e(543," 0.1"),o(544,"br"),i(545,"strong"),e(546,"penalty:"),t(),e(547," 'l1'"),o(548,"br"),i(549,"strong"),e(550,"solver:"),t(),e(551," 'saga' "),t(),i(552,"div",81),e(553," L1 regularization for feature selection and interpretability. "),t()()(),i(554,"app-window",73)(555,"div",79)(556,"div",80)(557,"strong"),e(558,"learning_rate:"),t(),e(559," 0.1"),o(560,"br"),i(561,"strong"),e(562,"max_depth:"),t(),e(563," 3"),o(564,"br"),i(565,"strong"),e(566,"n_estimators:"),t(),e(567," 200"),o(568,"br"),i(569,"strong"),e(570,"subsample:"),t(),e(571," 1.0 "),t(),i(572,"div",81),e(573," Gradual learning with conservative depth. All samples per iteration. "),t()()(),i(574,"app-window",83)(575,"div",79)(576,"div",80)(577,"strong"),e(578,"max_depth:"),t(),e(579," None"),o(580,"br"),i(581,"strong"),e(582,"min_samples_leaf:"),t(),e(583," 2"),o(584,"br"),i(585,"strong"),e(586,"min_samples_split:"),t(),e(587," 2"),o(588,"br"),i(589,"strong"),e(590,"n_estimators:"),t(),e(591," 100 "),t(),i(592,"div",81),e(593," Unconstrained tree growth. Minimal leaf requirements for flexibility. "),t()()()(),i(594,"h2",10),e(595,"Empirical Results"),t(),i(596,"div",14)(597,"div",15)(598,"h3",16),e(599,"Regression Performance"),t(),i(600,"div",84)(601,"app-window",85)(602,"div",86)(603,"div",87)(604,"div",88),e(605," RMSE (Test Set) "),t(),i(606,"div",89),e(607,"10,964.77"),t()(),i(608,"div",90),e(609," ElasticNet's combination of L1 and L2 regularization effectively balanced feature selection and generalization, achieving the best performance among all. "),t()()(),i(610,"app-window",91)(611,"div",92)(612,"div",93)(613,"span"),e(614,"Linear Regression"),t(),i(615,"span",41),e(616,"11,131"),t()(),i(617,"div",93)(618,"span",41),e(619,"ElasticNet"),t(),i(620,"span",94),e(621,"10,965"),t()(),i(622,"div",93)(623,"span"),e(624,"Random Forest"),t(),i(625,"span",41),e(626,"12,012"),t()(),i(627,"div",95)(628,"span"),e(629,"XGBoost"),t(),i(630,"span",41),e(631,"12,299"),t()()()()()(),i(632,"div",15)(633,"h3",16),e(634,"Classification Performance"),t(),i(635,"div",84)(636,"app-window",96)(637,"div",86)(638,"div",87)(639,"div",88),e(640," F1-Score / Accuracy "),t(),i(641,"div",89),e(642,"0.858 / 86.4%"),t()(),i(643,"div",90),e(644," Random Forest's ensemble approach achieved superior performance, with 95% recall on high-utilization patients (Class 1), enabling effective resource targeting. "),t()()(),i(645,"app-window",91)(646,"div",92)(647,"div",93)(648,"span"),e(649,"Logistic Regression"),t(),i(650,"span",41),e(651,"0.711"),t()(),i(652,"div",93)(653,"span"),e(654,"XGBoost"),t(),i(655,"span",41),e(656,"0.853"),t()(),i(657,"div",95)(658,"span",41),e(659,"Random Forest"),t(),i(660,"span",94),e(661,"0.858"),t()()()()()()(),i(662,"div",61)(663,"app-window",97)(664,"div",63),o(665,"canvas",null,2),t()()(),i(667,"div",98)(668,"button",99),T("click",function(){return b(d),w(l.toggleDetailedView())}),e(669),t(),C(670,q,69,0,"div",100),t(),i(671,"h2",10),e(672,"Feature Selection Experiments"),t(),i(673,"div",78),e(674," Recursive Feature Elimination with Cross-Validation (RFECV) and Sequential Feature Selection (SFS) were tested. Unexpectedly, both methods degraded performance with higher RMSE and lower R\xB2 values. This indicated that seemingly unimportant features contributed significantly when combined with others. Therefore, the full 108-feature set was retained for optimal results. "),t(),i(675,"div",29)(676,"app-window",101)(677,"div",102)(678,"div",103)(679,"strong"),e(680,"Finding:"),t(),e(681," Feature selection degraded performance "),t(),i(682,"div",104),e(683," Removing features that appeared individually weak still reduced model accuracy. Complex feature interactions are crucial. "),t(),i(684,"div",105)(685,"strong"),e(686,"Decision:"),t(),e(687," Retained full feature set "),t()()(),i(688,"app-window",106)(689,"div",102)(690,"div",103)(691,"strong"),e(692,"Implication:"),t(),e(693," Non-linear combinations matter "),t(),i(694,"div",104),e(695," Individual feature importance doesn't capture synergistic effects in ensemble and regularized models. "),t(),i(696,"div",107)(697,"strong"),e(698,"Result:"),t(),e(699," 108 features optimal "),t()()()(),i(700,"h2",10),e(701,"Key Findings & Insights"),t(),i(702,"div",29)(703,"app-window",108)(704,"ul",109)(705,"li"),e(706,"Regularized models outperform complex ensemble methods"),t(),i(707,"li"),e(708,"Medical expenditure highly variable"),t(),i(709,"li"),e(710,"Feature interactions critical to predictions"),t(),i(711,"li"),e(712,"L1+L2 balance most effective for this domain"),t()()(),i(713,"app-window",110)(714,"ul",109)(715,"li"),e(716,"Ensemble methods vastly superior (0.86 vs 0.71 F1)"),t(),i(717,"li"),e(718,"High recall for positive class (95%) is critical"),t(),i(719,"li"),e(720,"Imbalanced data handled well by models"),t(),i(721,"li"),e(722,"85% accuracy suitable for real-world deployment"),t()()()(),i(723,"h2",10),e(724,"Conclusion"),t(),i(725,"div",78),e(726," This project successfully developed robust predictive models for healthcare utilization. ElasticNet emerged as the optimal regression model (RMSE: 10,965), while Random Forest proved most effective for classification (F1: 0.858, 86.4% accuracy). The comprehensive preprocessing pipeline, feature engineering, and rigorous hyperparameter tuning ensured models capable of supporting clinical decision-making. Results demonstrate the viability of these approaches for patient stratification, resource allocation, and operational efficiency in healthcare systems. "),t()()()}n&2&&(m("technologies",z(18,G)),s(23),m("initialMinimized",!1),s(2),m("initialMinimized",!1),s(66),m("initialMinimized",!0),s(66),m("initialMinimized",!0),s(53),m("initialMinimized",!0),s(19),m("innerHTML",S(230,12,"\\log(\\text{TOT\\_INCOME} + 1)"),g),s(51),m("initialMinimized",!0),s(18),m("innerHTML",S(299,14,"x' = \\frac{x - \\min}{\\max - \\min}"),g),s(21),m("innerHTML",S(320,16,"z = \\frac{x - \\mu}{\\sigma}"),g),s(350),M(" ",l.showDetailedView?"\u2191 Hide Detailed Metrics":"\u2193 Show Detailed Metrics"," "),s(),m("ngIf",l.showDetailedView))},dependencies:[F,I,B,P],styles:["[_nghost-%COMP%]{--color-success: #22c55e}.light-theme[_nghost-%COMP%]{--color-success: #16a34a}.dark-theme[_nghost-%COMP%]{--color-success: #4ade80}.text-success[_ngcontent-%COMP%]{color:var(--color-success)}.config-window[_ngcontent-%COMP%]{border-left:4px solid var(--color-primary);background-color:rgb(var(--color-primary-rgb) / .05)}"]})};export{H as HealthcareUtilizationComponent};
